{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0de988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import konlpy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import urllib.request\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99723d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3aa9ffd488a5>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_table('최종네이버리뷰.txt', sep='/n')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"선불이고 브레이크 타임은 2시 30분부터 5시까지이고 1인당 9900원에 9가지 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가성비는 있는데 맛은 제 입에 안 맞았어요 탕수육은 맛있음 ??</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>음식 맛있어요사람들 정말 많아요다먹은후 그릇은셀프로 치워야해요^^짬뽕국물먹으러 또가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정말 맛있게 잘먹었습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12459</th>\n",
       "      <td>이문동에서 제일 인기많은 카페라고 생각이 드네요?? 분위기가 따스하고 안락하니 좋아요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12460</th>\n",
       "      <td>음료가 맛있고 수플레가 진짜 맛있어요!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12461</th>\n",
       "      <td>전체적으로 아늑한 분위기예요 화장실은 아쉬워요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12462</th>\n",
       "      <td>수플레 첨먹어보는뎅 맛있어요 살살 녹아용ㅎㅎ 양귀비아이스티도 짱맛!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12463</th>\n",
       "      <td>수플레 꼭드세요 두번드세요!!! 너무이쁘고 맛있어요!!!??\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12464 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence\n",
       "0                                                      0\n",
       "1      \"선불이고 브레이크 타임은 2시 30분부터 5시까지이고 1인당 9900원에 9가지 ...\n",
       "2                    가성비는 있는데 맛은 제 입에 안 맞았어요 탕수육은 맛있음 ??\n",
       "3      음식 맛있어요사람들 정말 많아요다먹은후 그릇은셀프로 치워야해요^^짬뽕국물먹으러 또가...\n",
       "4                                         정말 맛있게 잘먹었습니다.\n",
       "...                                                  ...\n",
       "12459   이문동에서 제일 인기많은 카페라고 생각이 드네요?? 분위기가 따스하고 안락하니 좋아요.\n",
       "12460                              음료가 맛있고 수플레가 진짜 맛있어요!\n",
       "12461                          전체적으로 아늑한 분위기예요 화장실은 아쉬워요\n",
       "12462              수플레 첨먹어보는뎅 맛있어요 살살 녹아용ㅎㅎ 양귀비아이스티도 짱맛!\n",
       "12463                 수플레 꼭드세요 두번드세요!!! 너무이쁘고 맛있어요!!!??\"\n",
       "\n",
       "[12464 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력 데이터프레임은 다음과 같은 양식으로 통일할 것\n",
    "df = pd.read_table('최종네이버리뷰.txt', sep='/n')\n",
    "df = df[['document']]\n",
    "df = df.rename(columns={\"document\": \"sentence\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4586a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_dic = pd.read_csv('SentiWord_Dict.txt',sep = '\\t',header=None)\n",
    "sent_dic.iloc[14850,0]='갈등'\n",
    "\n",
    "pos_dic = sent_dic[sent_dic[1]>0]\n",
    "neg_dic = sent_dic[sent_dic[1]<0]\n",
    "neu_dic = sent_dic[sent_dic[1]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57260a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>건강에 긍정적인</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>건강에 좋은</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>건강에 해로운</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>건강하고</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>건강하고 온전하다</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>건강하고 온전한</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>건강하다</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>건강하여</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>건강하여 아름다운</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>건강하지 못하다</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>건강한</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>건달처럼</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>건둥건둥</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>건둥건둥하다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>건둥반둥하다</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>건드려 귀찮게</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>건들거리고</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>건들거리고 벙글거리며</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  1\n",
       "632     건강에 긍정적인  1\n",
       "633       건강에 좋은  2\n",
       "634      건강에 해로운 -2\n",
       "635         건강하고  2\n",
       "636    건강하고 온전하다  2\n",
       "637     건강하고 온전한  2\n",
       "638         건강하다  2\n",
       "639         건강하여  2\n",
       "640    건강하여 아름다운  2\n",
       "641     건강하지 못하다 -1\n",
       "642          건강한  2\n",
       "643         건달처럼 -1\n",
       "644         건둥건둥  1\n",
       "645       건둥건둥하다  1\n",
       "646       건둥반둥하다 -1\n",
       "647      건드려 귀찮게 -1\n",
       "648        건들거리고 -1\n",
       "649  건들거리고 벙글거리며 -1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dic[632:650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3fe1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = konlpy.tag.Okt()\n",
    "\n",
    "def text_preprocess(x):\n",
    "    text=[]\n",
    "    a = re.sub('[^가-힣0-9a-zA-Z\\\\s]', '',x)\n",
    "    for j in a.split():\n",
    "        text.append(j)\n",
    "    return ' '.join(text)\n",
    "\n",
    "def tokenize(x):\n",
    "    text = []\n",
    "    tokens = okt.pos(x)\n",
    "    for token in tokens :\n",
    "        if token[1] == 'Adjective' or token[1]=='Adverb' or token[1] == 'Determiner' or token[1] == 'Noun' or token[1] == 'Verb' or 'Unknown':\n",
    "            text.append(token[0])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "325aa226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▊                                                              | 2266/12464 [00:11<00:52, 193.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-20df15c844d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtext_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[1;31m# on the df using our wrapper (which provides bar updating)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 810\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    811\u001b[0m                 \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    812\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    803\u001b[0m                     \u001b[1;31m# take a fast or slow code path; so stop when t.total==t.n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m                 \u001b[1;31m# Apply the provided function (in **kwargs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-20df15c844d8>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtext_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'comment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogress_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-cae3c8bccc82>\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Adjective'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Adverb'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Determiner'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Noun'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Verb'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'Unknown'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     71\u001b[0m         tokens = self.jki.tokenize(\n\u001b[0;32m     72\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                     \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                     jpype.java.lang.Boolean(stem)).toArray()\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "tqdm.pandas()\n",
    "df['comment'] = df['sentence'].apply(lambda x : text_preprocess(x))\n",
    "df['comment'] = df['comment'].progress_apply(lambda x: tokenize(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9410e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_sent_dict(x) :\n",
    "    pos=[]\n",
    "    neg=[]\n",
    "    tmp={}\n",
    "    \n",
    "    for sentence in tqdm(x):\n",
    "        for word in sentence :\n",
    "            target = sent_dic[sent_dic[0]==word]\n",
    "            if len(target)==1: # 기존에 있는 단어라면 그대로 사용\n",
    "                score = float(target[1])\n",
    "                if score > 0:\n",
    "                    pos.append(word)\n",
    "                elif score < 0:\n",
    "                    neg.append(word)                \n",
    "            tmp[word] = {'W':0,'WP':0,'WN':0} # 감성사전 구성\n",
    "    pos = list(set(pos))\n",
    "    neg = list(set(neg))\n",
    "    \n",
    "    for sentence in tqdm(x):\n",
    "        for word in sentence :\n",
    "            tmp[word]['W'] += 1 # 빈도 수\n",
    "            for po in pos :\n",
    "                if po in sentence:\n",
    "                    tmp[word]['WP'] += 1 # 긍정단어과 같은 문장 내 단어일 때\n",
    "                    break\n",
    "            for ne in neg:\n",
    "                if ne in sentence:\n",
    "                    tmp[word]['WN'] += 1 # 부정단어와 같은 문장내 단어일 때\n",
    "                    break\n",
    "    return pos, neg, pd.DataFrame(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0548950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pos, neg, new_dict = make_sent_dict(df['comment'].values)\n",
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802dce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_score_dict(d,p,n):\n",
    "    N=sum(d.iloc[0,::])\n",
    "    pos_cnt=sum(d.loc[::,p].iloc[0,::])\n",
    "    neg_cnt=sum(d.loc[::,n].iloc[0,::])\n",
    "    \n",
    "    trans =d.T\n",
    "    trans['neg_cnt']=neg_cnt\n",
    "    trans['pos_cnt']=pos_cnt\n",
    "    trans['N']=N\n",
    "\n",
    "    trans['MI_P']=np.log2(trans['WP']*trans['N']/trans['W']*trans['pos_cnt'])\n",
    "    trans['MI_N']=np.log2(trans['WN']*trans['N']/trans['W']*trans['neg_cnt'])\n",
    "    trans['SO_MI']=trans['MI_P'] - trans['MI_N']\n",
    "    \n",
    "    trans = trans.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "    trans = trans.sort_values(by=['SO_MI'],ascending=False)\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49975260",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_dict = make_score_dict(new_dict,pos,neg)\n",
    "t_dict['SO_MI'] = scaler.fit_transform(t_dict['SO_MI'].values.reshape(-1,1))\n",
    "t_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42197d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_dict(d):\n",
    "    add_Dic = {0:[],1:[]}\n",
    "    for i in d.T.items():\n",
    "        if i[0] not in list(sent_dic[0]):\n",
    "            if len(i[0]) > 1:\n",
    "                add_Dic[0].append(i[0])\n",
    "                add_Dic[1].append(i[1]['SO_MI'])\n",
    "            \n",
    "    add_Dic=pd.DataFrame(add_Dic)\n",
    "    Sentiment=pd.merge(sent_dic,add_Dic,'outer')\n",
    "    return Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5d24db",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dict =update_dict(t_dict)\n",
    "add_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbd17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_cnt(x):\n",
    "    cnt = 0\n",
    "    for word in list(set(x)):\n",
    "        target = add_dict[add_dict[0]==word]\n",
    "        if len(target)==1:\n",
    "            cnt += float(target[1])\n",
    "    return cnt\n",
    "\n",
    "def get_ratio(x):\n",
    "    score = x['score']\n",
    "    length = np.log10(len(x['comment']))+1\n",
    "    try:\n",
    "        ratio= round(score/length,2)\n",
    "    except:\n",
    "        ratio = 0\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df['score']= df['comment'].progress_apply(lambda x : get_cnt(x))\n",
    "df['ratio'] = df.apply(lambda x: get_ratio(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800a0050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aurora3:\n",
    "    \n",
    "    def __init__(self, df,sent_dic):\n",
    "        self.df = df\n",
    "        self.okt = konlpy.tag.Okt()\n",
    "        self.sent_dic = sent_dic\n",
    "        \n",
    "    def get_df(self):# 최종 결과 반환\n",
    "        print(\"문장을 토큰화 중입니다...\")\n",
    "        self.tokenizer_run()\n",
    "        \n",
    "        print(\"감성사전을 업데이트 중입니다...\")\n",
    "        self.expand_sent_dic()\n",
    "        \n",
    "        print(\"문장 감성분석 중입니다....\")\n",
    "        self.sent_analyze()\n",
    "        return self.df\n",
    "        \n",
    "    def tokenizer_run(self): # 텍스트 전처리 & 토큰화\n",
    "        tqdm.pandas()\n",
    "        \n",
    "        def text_preprocess(x):\n",
    "            text=[]\n",
    "            a = re.sub('[^가-힣0-9a-zA-Z\\\\s]', '',x)\n",
    "            for j in a.split():\n",
    "                text.append(j)\n",
    "            return ' '.join(text)\n",
    "\n",
    "        def tokenize(x):\n",
    "            text = []\n",
    "            tokens = self.okt.pos(x)\n",
    "            for token in tokens :\n",
    "                if token[1] == 'Adjective' or token[1]=='Adverb' or token[1] == 'Determiner' or token[1] == 'Noun' or token[1] == 'Verb' or 'Unknown':\n",
    "                    text.append(token[0])\n",
    "            return text\n",
    "        self.df['comment'] = self.df['sentence'].apply(lambda x : text_preprocess(x))\n",
    "        self.df['comment'] = self.df['comment'].progress_apply(lambda x: tokenize(x))\n",
    "    \n",
    "    def expand_sent_dic(self):\n",
    "        sent_dic = self.sent_dic\n",
    "        \n",
    "        def make_sent_dict(x) :\n",
    "            pos=[]\n",
    "            neg=[]\n",
    "            tmp={}\n",
    "\n",
    "            for sentence in tqdm(x):\n",
    "                for word in sentence :\n",
    "                    target = sent_dic[sent_dic[0]==word]\n",
    "                    if len(target)==1: # 기존에 있는 단어라면 그대로 사용\n",
    "                        score = float(target[1])\n",
    "                        if score > 0:\n",
    "                            pos.append(word)\n",
    "                        elif score < 0:\n",
    "                            neg.append(word)                \n",
    "                    tmp[word] = {'W':0,'WP':0,'WN':0} # 감성사전 구성\n",
    "            pos = list(set(pos))\n",
    "            neg = list(set(neg))\n",
    "\n",
    "            for sentence in tqdm(x):\n",
    "                for word in sentence :\n",
    "                    tmp[word]['W'] += 1 # 빈도 수\n",
    "                    for po in pos :\n",
    "                        if po in sentence:\n",
    "                            tmp[word]['WP'] += 1 # 긍정단어과 같은 문장 내 단어일 때\n",
    "                            break\n",
    "                    for ne in neg:\n",
    "                        if ne in sentence:\n",
    "                            tmp[word]['WN'] += 1 # 부정단어와 같은 문장내 단어일 때\n",
    "                            break\n",
    "            return pos, neg, pd.DataFrame(tmp)\n",
    "        \n",
    "        def make_score_dict(d,p,n):\n",
    "            N=sum(d.iloc[0,::])\n",
    "            pos_cnt=sum(d.loc[::,p].iloc[0,::])\n",
    "            neg_cnt=sum(d.loc[::,n].iloc[0,::])\n",
    "\n",
    "            trans =d.T\n",
    "            trans['neg_cnt']=neg_cnt\n",
    "            trans['pos_cnt']=pos_cnt\n",
    "            trans['N']=N\n",
    "\n",
    "            trans['MI_P']=np.log2(trans['WP']*trans['N']/trans['W']*trans['pos_cnt'])\n",
    "            trans['MI_N']=np.log2(trans['WN']*trans['N']/trans['W']*trans['neg_cnt'])\n",
    "            trans['SO_MI']=trans['MI_P'] - trans['MI_N']\n",
    "\n",
    "            trans = trans.replace([np.inf, -np.inf], np.nan).dropna(axis=0)\n",
    "            trans = trans.sort_values(by=['SO_MI'],ascending=False)\n",
    "            return trans\n",
    "        \n",
    "        def update_dict(d):\n",
    "            add_Dic = {0:[],1:[]}\n",
    "            for i in d.T.items():\n",
    "                if i[0] not in list(sent_dic[0]):\n",
    "                    if len(i[0]) > 1:\n",
    "                        add_Dic[0].append(i[0])\n",
    "                        add_Dic[1].append(i[1]['SO_MI'])\n",
    "\n",
    "            add_Dic=pd.DataFrame(add_Dic)\n",
    "            Sentiment=pd.merge(sent_dic,add_Dic,'outer')\n",
    "            return Sentiment\n",
    "        \n",
    "        self.pos, self.neg, self.new_dict = make_sent_dict(self.df['comment'].values)\n",
    "        \n",
    "        self.t_dict = make_score_dict(self.new_dict,self.pos,self.neg)\n",
    "        self.t_dict['SO_MI'] = scaler.fit_transform(self.t_dict['SO_MI'].values.reshape(-1,1))\n",
    "       \n",
    "        self.add_dict =update_dict(self.t_dict)\n",
    "    \n",
    "    def sent_analyze(self): # 데이터 감성분석\n",
    "        tqdm.pandas()\n",
    "        \n",
    "        def get_cnt(x):\n",
    "            cnt = 0\n",
    "            for word in list(set(x)):\n",
    "                target = self.add_dict[self.add_dict[0]==word]\n",
    "                if len(target)==1:\n",
    "                    cnt += float(target[1])\n",
    "            return cnt\n",
    "\n",
    "        def get_ratio(x):\n",
    "            score = x['score']\n",
    "            length = np.log10(len(x['comment']))+1\n",
    "            try:\n",
    "                ratio= round(score/length,2)\n",
    "            except:\n",
    "                ratio = 0\n",
    "            return ratio\n",
    "        \n",
    "        tqdm.pandas()\n",
    "        self.df['score']= self.df['comment'].progress_apply(lambda x : get_cnt(x))\n",
    "        self.df['ratio'] = self.df.apply(lambda x: get_ratio(x), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc079166",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Aurora3(df,sent_dic)\n",
    "res = test.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909aa7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612f0031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e0998f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res[458:477]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res.to_csv('네이버리뷰감성점수.csv', encoding='cp949',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93df045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
